#!/usr/bin/env python


'''
given the segmented and pose normalized subtomograms generated by
~/ln/tomominer/tomominer/pick/pose_normalize_segmentation_batch_run_json.py
perform k-means clustering, store cluster centers and labels, create subfolders for each cluster and store data_json for each each cluster

'''

import os
import sys
import json
import numpy as N
import random
import sklearn.cluster as SC

import tomominer.io.file as IF

if __name__ == '__main__':

    with open('pose_normalize_cluster_kmeans__op.json') as f:    op = json.load(f)

    with open(op['data_json_file']) as f:    dj = json.load(f)

    if 'test' in op:
        if ('sample_num' in op['test']) and (op['test']['sample_num'] > 0) and (len(dj) > op['test']['sample_num']):
            print 'testing the procedure using a subsample of %d subtomograms'%(op['test']['sample_num'])
            dj = random.sample(dj, op['test']['sample_num'])


    # collect segmented and pose normalized subtomograms
    x = None
    size = None
    for i, d in enumerate(dj):
        print '\r', i, float(i) / len(dj), '            ',          ;       sys.stdout.flush()

        v = IF.read_mrc(d['segmentation']['pose']['subtomogram'])['value']

        if x is None:
            x = N.zeros( (len(dj), v.size) )
            size = v.shape

        x[i, :] = v.flatten()
    

    km = SC.KMeans(n_clusters=op['cluster_num'], n_jobs=op['n_jobs'], verbose=3)
    lbl = km.fit_predict(x)

    for i in range(len(dj)):    dj[i]['cluster_label'] = int(lbl[i])

    with open('pose_normalize_cluster_kmeans__out.json', 'w') as f:    json.dump(dj, f, indent=2)


    out_dir = os.path.abspath(op['out_dir'])
    if not os.path.isdir(out_dir):  os.makedirs(out_dir)

    # export cluster centers
    for l in range(op['cluster_num']):
        v = km.cluster_centers_[l,:].flatten()
        v = N.reshape(v, size)
        
        IF.put_mrc(v, os.path.join(out_dir, 'clus_vol_avg_%03d.mrc'%(l,)), overwrite=True) 



    # export data_json respect to individual clusters
    cluster_sizes = {}
    for l in range(op['cluster_num']):
        dj_t = [_ for _ in dj if (_['cluster_label'] == l)]

        cluster_sizes[l] = len(dj_t)
        print   'cluster', l, 'size', cluster_sizes[l]
        
        clus_dir = os.path.join(os.path.abspath(op['out_dir']), str(l))
        if not os.path.isdir(clus_dir):  os.makedirs(clus_dir)

        with open(os.path.join(clus_dir, 'data_config.json'), 'w') as f:     json.dump(dj_t, f, indent=2)


    with open('pose_normalize_cluster_kmeans__out__cluster_sizes.json', 'w') as f:    json.dump(cluster_sizes, f, indent=2)

